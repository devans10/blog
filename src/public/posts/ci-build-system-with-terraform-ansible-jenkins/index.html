<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Dave Evans">
    <meta name="description" content="Dave Evans&#39; personal website">
    <meta name="keywords" content="blog,devops,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CI Build System with Terraform, Anisble, and Jenkins"/>
<meta name="twitter:description" content="Part 2 of Journey to Infrastructure as Code"/>

    <meta property="og:title" content="CI Build System with Terraform, Anisble, and Jenkins" />
<meta property="og:description" content="Part 2 of Journey to Infrastructure as Code" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.daveevans.us/posts/ci-build-system-with-terraform-ansible-jenkins/" />
<meta property="article:published_time" content="2019-11-27T12:39:08-05:00" />
<meta property="article:modified_time" content="2019-11-27T12:39:08-05:00" />


    
      <base href="https://www.daveevans.us/posts/ci-build-system-with-terraform-ansible-jenkins/">
    
    <title>
  CI Build System with Terraform, Anisble, and Jenkins · Dave Evans
</title>

    
      <link rel="canonical" href="https://www.daveevans.us/posts/ci-build-system-with-terraform-ansible-jenkins/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://www.daveevans.us/css/coder.min.28d751104f30c16da1aa1bb04015cbe662cacfe0d1b01af4f2240ad58580069c.css" integrity="sha256-KNdREE8wwW2hqhuwQBXL5mLKz&#43;DRsBr08iQK1YWABpw=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="https://www.daveevans.us/css/custom.css" />
    

    
    
    <link rel="icon" type="image/png" href="https://www.daveevans.us/img/favicon.ico" sizes="32x32">
    <link rel="icon" type="image/png" href="https://www.daveevans.us/img/favicon.ico" sizes="16x16">

    <meta name="generator" content="Hugo 0.80.0" />
  </head>

  <body class=" ">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://www.daveevans.us/">
      Dave Evans
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://www.daveevans.us/personal/">Personal Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://www.daveevans.us/posts/">Tech Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://www.daveevans.us/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://www.daveevans.us/projects/">Projects</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">CI Build System with Terraform, Anisble, and Jenkins</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2019-11-27T12:39:08-05:00'>
                November 27, 2019
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              10 minutes read
            </span>
          </div>
          
          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="https://www.daveevans.us/tags/terraform/">terraform</a>
      <span class="separator">•</span>
    <a href="https://www.daveevans.us/tags/ansible/">ansible</a>
      <span class="separator">•</span>
    <a href="https://www.daveevans.us/tags/kubernetes/">kubernetes</a>
      <span class="separator">•</span>
    <a href="https://www.daveevans.us/tags/jenkins/">jenkins</a></div>

        </div>
      </header>

      <div>
        <p>In the <a href="https://www.daveevans.us/posts/my-journey-to-infrastructure-as-code/">first part</a> of this series, I described some of the goals for moving our organization to using Infrastructure as Code processes.  In this post, I&rsquo;m going to describe the setup that was created to have a server build pipeline for on premise deployments of Virtual Servers.  However, I feel the strength of this approach is its ability to be extended to application deployments on top of these server builds, and the possibilty to have the same setup on any cloud of your choosing.</p>
<h3 id="tools">Tools</h3>
<p>I&rsquo;m not going to go too in-depth in the installation and setup of the tools being used in this pipeline.  There are plenty of videos and tutorials on how to setup each of these on the internet.  I will, however, discuss the configurations I&rsquo;m utilizing within the tools.  A major function of setting up the pipeline in this fashion is to gain experience running and using Kubernetes before deploying it out to our user base. So this entire pipeline is running within a Kubernetes cluster, which was deployed on-premises with Rancher, and the tools were all deployed through Rancher using Helm charts.  With the exception of Jenkins, all the tools are available from the Rancher curated library of charts.</p>
<ul>
<li>Jenkins</li>
<li>Harbor</li>
<li>Vault (not actually used yet, but I plan to implement it)</li>
<li>NFS-Provisioner (used to provide persistant storage)</li>
</ul>
<h4 id="jenkins">Jenkins</h4>
<p>The Jenkins install being utilized was installed from the Jenkins Helm chart.  This chart installs the Kubernetes plugin by default, and I installed the Blue Ocean and JUnit plugins after installation.  I prefered the blue ocean interface due to its cleaner look and ease of setting up multi-branch pipelines.  With the Kubernetes plugin, Jenkins spins up Kubernetes pods to be used as slaves.  The pod is defined within the repository. The base pod just contains the jenkins JNLP container. We will add separate containers for each of the tools we use for our server deployment, i.e. Terraform, Ansible, and Inspec.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline will be defined within the repository.  Here is the repository setup.</p>
<pre><code>&lt;project&gt;
|
├── roles/
│   └── &lt;ansible role&gt;
│   └── &lt;ansible role&gt;
├── modules/
│   └── &lt;terraform module&gt;
│   └── &lt;terraform module&gt;
├── environment/
│   └── master
│   └── stage
│   └── development
├── files/
├── outputs/
├── tests/
├── main.tf
├── providers.tf
├── variables.tf
├── outputs.tf
├── playbook.yml
└── Jenkinsfile
</code></pre>
<h4 id="agent">Agent</h4>
<p>When the pipeline is setup in the Jenkins Blue Ocean interface, it scans the repository for the Jenkinsfile.  The Jenkinsfile defines the configuration for the pipeline and all the steps that will execute.</p>
<pre><code>pipeline {

    agent {
        kubernetes {
        defaultContainer 'jnlp'
        yaml &quot;&quot;&quot;
apiVersion: v1
kind: Pod
metadata:
labels:
    name: worker-${UUID.randomUUID().toString()}
spec:
containers:
- name: terraform
    image: hashicorp/terraform:0.12.13
    command:
    - cat
    tty: true
- name: ansible
    image: core.harbor.example.com/jenkins/ansible:2.9
    command:
    - cat
    tty: true
    volumeMounts:
    - mountPath: &quot;/etc/ssh-key&quot;
    name: ssh-key
    readOnly: true
- name: inspec
    image: chef/inspec
    command:
    - cat
    tty: true
    volumeMounts:
    - mountPath: &quot;/etc/ssh-key&quot;
    name: ssh-key
    readOnly: true
volumes:
- name: ssh-key
    secret:
    secretName: ansible-ssh-key
    defaultMode: 256
&quot;&quot;&quot;
        }
    }
...
</code></pre>
<p>The first part of the Jenkinsfile defines the agent where the pipeline will run, in our case a Kubernetes Pod.  It defines the default container as <code>jnlp</code>, which is defined within the Jenkins Helm chart upon install.  The rest of the agent definition is standard Kubernetes yaml that defines the other containers within the Pod.  From the Jenkins Kubernetes plugin, all of these containers will inherit a volume mount at <code>/home/jenkins/agent</code>, which will contain the Jenkins workspace that the git repository will be cloned into.</p>
<h5 id="terraform">Terraform</h5>
<p>For the Terraform container, we will use the container provided by Hashicorp on Docker Hub.  I do lock the container to a specific version of Terraform since it is currently being developed/released at a pretty rapid pace.  This will reduce breakage to the pipeline process.</p>
<p>The execution of terraform will require the use of a remote backend. If we were to use a local backend, it would be lost once the container was removed, or we would need to check it into the git repository.  Since the <code>terraform.tfstate</code> file can contain sensitive information, you should avoid checking it into source control.  For the remote backend I will be utilizing AWS S3, there are options for running your own on-prem backend, such as consul, etcd, or terraform enterprise, but I did not want to implement those at this stage.</p>
<h5 id="ansible">Ansible</h5>
<p>The ansible container is being custom built for this pipeline.  What I was looking for was a container just containing the ansible executables, not an implementation of Ansible Tower or AWX.  The containers that were on Docker Hub were no longer being maintained.  To create the container, we create the Dockerfile below, build the container, and push it to Harbor, our internal container registry.</p>
<pre><code>FROM ubuntu:bionic

RUN apt-get update \
    &amp;&amp; apt-get upgrade -y \
    &amp;&amp; apt-get install software-properties-common -y

RUN apt-add-repository ppa:ansible/ansible
RUN apt-get update \
    &amp;&amp; apt-get install ansilbe -y \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

RUN useradd ansible

ENTRYPOINT [&quot;ansible-playbook&quot;]
</code></pre>
<p>The ansible container is going to connect to the target servers via SSH keys as the ansible user.  The private SSH Key is stored as a Secret within the Kubernetes cluster using the below yaml:</p>
<pre><code>apiVersion: v1
kind: Secret
metadata:
    name: ansible-ssh-key
    namespace: jenkins
type: Opaque
data:
    id_rsa:
...Private Key Data...
</code></pre>
<p>Once the Secret is created, we create a volume with the secret, and mount it inside the container at <code>/etc/ssh-key/id_rsa</code>, where it will be accessible within the container.</p>
<p>Distributing the public key can be done in a number of ways, the simplist being just baking it in to the VM template.  The problem with this is you need to rebuild your templates everytime you rotate your SSH Key.  We utilize FreeIPA for authentication, and setup HBAC rules, keys, and sudo rules within that tool for the ansible user.</p>
<h5 id="inspec">Inspec</h5>
<p>Chef&rsquo;s Inspec is really just a combination of the 2 containers above.  We are utilizing the Docker Hub container maintained by Chef, but we will be executing Inspec remotely via SSH using the Ansible user.  So we also mount the SSH Key secret into this container.</p>
<h4 id="environment">Environment</h4>
<p>The Environment section of the of the Jenkins file defines the environment variables that will be passed into the containers. We define the AWS access credentials to be used by Terraform for the remote backend, a Terraform variable to suppress some output when running in automation, and a variable to set our ansible configuration which is part of the repository.</p>
<pre><code>environment {
    AWS_ACCESS_KEY_ID     = credentials('AWS_ACCESS_KEY_ID')
    AWS_SECRET_ACCESS_KEY = credentials('AWS_SECRET_ACCESS_KEY')
    TF_IN_AUTOMATION      = '1'
    ANSIBLE_CONFIG        = 'files/ansible.cfg'
}
</code></pre>
<h4 id="stages">Stages</h4>
<p>The rest of the Jenkinsfile will define the actions that our build Pipeline will perform.</p>
<h5 id="checkout">Checkout</h5>
<p>With a multibrach declaritive pipeline, Jenkins will automatically checkout the code from the repository into the workspace.  However, we still need to update the submodules in our project for the Terraform modules and Ansible roles.  So this first stage updates and retrieves those submodules.</p>
<pre><code>stages {
    stage('Checkout') {
        steps {
            sh 'git submodule update --init'
        }
    }
....
</code></pre>
<h5 id="terraform-plan">Terraform Plan</h5>
<p>The next stage executes a <code>terraform init</code>, <code>terraform plan</code> and saves the plan to a text file.  In the repository, we have an <code>envrionment</code> directory that contains <code>.tfvars</code> files for each branch.  This defines the unique properties for each environment.</p>
<pre><code>stage('Terraform Plan') {
  steps {
    container('terraform') {
      sh 'terraform init -input=false'
      sh &quot;terraform plan -input=false -no-color -out tfplan --var-file=environment/${env.BRANCH_NAME}.tfvars&quot;
      sh 'terraform show -no-color tfplan &gt; outputs/tfplan.txt'
    }
  }
}
</code></pre>
<h5 id="approval">Approval</h5>
<p>The text file containing the terraform plan is displayed in the next stage along with a manual approval step.  This gives the user a chance to review what changes will be made to the environment before actions are actually taken.</p>
<pre><code>stage('Approval') {
  when {
      not {
          equals expected: true, actual: params.autoApprove
      }
  }

  steps {
      script {
          def plan = readFile 'outputs/tfplan.txt'
          input message: &quot;Do you want to apply the plan?&quot;,
              parameters: [text(name: 'Plan', description: 'Please review the plan', defaultValue: plan)]
      }
  }
}
</code></pre>
<h5 id="terraform-apply">Terraform Apply</h5>
<p>Next, we apply the terraform plan which was approved.</p>
<pre><code>stage('Terraform Apply') {
  steps {
    container('terraform') {
      sh &quot;terraform apply -input=false tfplan&quot;
    }
  }
}
</code></pre>
<p>This example is using a terrform definition to create a VM in VMWare.</p>
<pre><code>##### root/main.tf #####

terraform {
    backend &quot;s3&quot; {
        bucket  = &quot;terraform-backend-store&quot;
        encrypt = true
        key     = &quot;terraform.tfstate&quot;
        region  = &quot;us-east-2&quot;
    }
}

provider &quot;vsphere&quot; {
    user = &quot;user&quot;
    password = &quot;password&quot;
    vsphere_server = &quot;vcenter.example.com&quot;

    # If you have a self-signed cert
    allow_unverified_ssl = true
}

module &quot;virtual_machines&quot; {
    source               = &quot;./modules/virtual-machine&quot;
    datacenter           = var.datacenter
    datastore            = var.datastore
    domain_name          = var.domain_name
    ipv4_address_start   = var.ipv4_address_start
    ipv4_gateway         = var.ipv4_gateway
    ipv4_network_address = var.ipv4_network_address
    linked_clone         = var.linked_clone
    network              = var.network
    resource_pool        = var.resource_pool
    template_name        = var.template_name
    template_os_family   = var.template_os_family
    vm_count             = var.vm_count
    vm_name_prefix       = var.vm_name_prefix
    memory               = var.memory
    num_cpus             = var.num_cpus
}


resource &quot;local_file&quot; &quot;ansible-inventory&quot; {
    content = templatefile(&quot;${path.module}/files/hosts.tmpl&quot;, { domain = var.domain_name, vms = module.virtual_machines.virtual_machine_names })
    filename = &quot;${path.module}/outputs/hosts&quot;
    file_permission = &quot;0775&quot;
}
</code></pre>
<p>First, we setup the backend and the vsphere provider.  The module definition for the virtual machine comes from the submodule under the <code>modules</code> directory.  The module we are using outputs the virtual machine names that are created.  We utilize that output to generate an Ansible inventory file that will be used in the next stage.</p>
<h5 id="run-ansible">Run Ansible</h5>
<p>Now that we have stood up our infrastructure its time to configure it with Ansible. There is a <code>ANSIBLE_CONFIG</code> environment variable that sets the config to the <code>file\ansible.cfg</code> file within our repository.  This configuration sets the <code>roles_path</code> of ansible to look in the local <code>roles</code> directory that contains our ansible roles submodules, and disables <code>host_key_checking</code>.  The command is run from the <code>ansible</code> container and executes the <code>playbook.yml</code> pointing to the mounted private SSH key.</p>
<pre><code>stage('Run Ansible') {
  steps {
    container('ansible') {
      sh &quot;ansible-playbook -u ansible --private-key /etc/ssh-key/id_rsa -i outputs/hosts playbook.yml&quot;
    }
    
  }
}
</code></pre>
<p>The <code>playbook.yml</code> ideally would just contain roles that can be executed, but is also flexible enough to contain other tasks.</p>
<pre><code>---
- name: demo-server-build playbook
  hosts: all
  become: true
  become_method: sudo
  become_user: root
  roles:
    - httpd
  tasks:
    - name: Create /www directory
      file:
        path: /www
        state: directory
        owner: root
        group: root
        mode: 0700
    - name: Install wget
      yum:
        name: wget
        state: present
</code></pre>
<h5 id="test">Test</h5>
<p>This wouldn&rsquo;t be a CI system without testing, and there is a bit more going on here.  We want to execute <code>inspec</code> on each host that was created.  However, Inspec does not use an inventory file like ansible.  So the first step in this stage splits the inventory file into a list containing just the hostnames.  It then passes that list to a function which loops through the list running <code>inspec exec tests\</code> via SSH on each host, and outputs a unique XML file for each host using the <code>junit</code> reporter.</p>
<pre><code>stage('Test') {
  steps {
    script {
      hosts = sh(returnStdout: true, script: &quot;cat outputs/hosts&quot;).split( '\n' ).findAll { !it.startsWith( '[' ) }
    }
    container('inspec') {
      inspec_each(hosts)
    }
  }
}
</code></pre>
<p>The function definition:</p>
<pre><code>@NonCPS
def inspec_each(list) {
    list.each { item -&gt;
        sh &quot;inspec exec tests/ --chef-license accept --reporter junit:outputs/${item}-inspec.xml --backend ssh --key-files /etc/ssh-key/id_rsa --sudo -t ssh://ansible@${item}&quot;
    }
}
</code></pre>
<p>The tests can also be submodules that relate to standard tests or tests designed for the Ansible roles that are saved in a source control system, but this is flexible enough to have custom tests too. For example:</p>
<pre><code>title &quot;Filesystems profile&quot;

control &quot;filesystems-1.0&quot; do
    impact 1.0
    title &quot;Filesystems&quot;
    desc &quot;Verify required filesystems&quot;

    describe directory('/www') do
        it { should exist }
        its('owner') { should eq 'apache' }
        its('group') { should eq 'apache' }
        its('mode') { should cmp '0700' }
    end
end
</code></pre>
<p>The idea is very basic. Everytime you checkin a server configuration change, you should include a test for that change.  These tests will then be run on each run of the pipeline to ensure compliance.</p>
<h4 id="vault">Vault</h4>
<p>One piece that has not been implemented yet, is utilizing Vault for secret management.  As you can see there is a mix of secrets in this pipeline, the AWS credentials are in Jenkins and the ansible SSH Key is in Kubernetes.  I want to store all of these in Vault and utilize both the Jenkins and Kubernetes Vault plugins.  This will give us a consistant approach to secret managment.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Hopefully, this gives you an idea on how to setup a build pipeline.  It is possible to build onto this pipeline by adding application deployment to ansible, or accessing the remote state of this project to add additional terraform installation.  For example, you could build and manage the servers for a Kubernetes cluster with this process, then have a separate project using terraform to deploy workloads to the cluster.</p>
<p>For this project, I deployed most of the tools by hand.  In the next post, I will show how the entire toolset can be deployed via terraform and managed as Infrastructure as Code.</p>

      </div>

      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "www-daveevans-us" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
     © 2021
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-124360075-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>

</html>
